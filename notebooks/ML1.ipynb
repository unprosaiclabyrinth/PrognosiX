{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f98a05e",
   "metadata": {},
   "source": [
    "#### ML Analysis #1: Attempt to create a model that can accurately classify whether the patient has CKD.\n",
    "\n",
    "Yash Dhore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7918b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2211c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the (preprocessed) data\n",
    "df = pd.read_csv(\"ckd_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedb353",
   "metadata": {},
   "source": [
    "Encode categorical variables to numerical form so that they can be trained upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff7a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object columns: []\n",
      "      age    bp     sg   al   su  rbc  pc  pcc  ba         bgr  ...   pcv  \\\n",
      "0    48.0  80.0  1.020  1.0  0.0    1   1    0   0  121.000000  ...  44.0   \n",
      "1     7.0  50.0  1.020  4.0  0.0    1   1    0   0  148.036517  ...  38.0   \n",
      "2    62.0  80.0  1.010  2.0  3.0    1   1    0   0  423.000000  ...  31.0   \n",
      "3    48.0  70.0  1.005  4.0  0.0    1   0    1   0  117.000000  ...  32.0   \n",
      "4    51.0  80.0  1.010  2.0  0.0    1   1    0   0  106.000000  ...  35.0   \n",
      "..    ...   ...    ...  ...  ...  ...  ..  ...  ..         ...  ...   ...   \n",
      "395  55.0  80.0  1.020  0.0  0.0    1   1    0   0  140.000000  ...  47.0   \n",
      "396  42.0  70.0  1.025  0.0  0.0    1   1    0   0   75.000000  ...  54.0   \n",
      "397  12.0  80.0  1.020  0.0  0.0    1   1    0   0  100.000000  ...  49.0   \n",
      "398  17.0  60.0  1.025  0.0  0.0    1   1    0   0  114.000000  ...  51.0   \n",
      "399  58.0  80.0  1.025  0.0  0.0    1   1    0   0  131.000000  ...  53.0   \n",
      "\n",
      "         wc        rc  htn  dm  cad  appet  pe  ane  classification  \n",
      "0    7800.0  5.200000    1   1    0      0   0    0               0  \n",
      "1    6000.0  4.707435    0   0    0      0   0    0               0  \n",
      "2    7500.0  4.707435    0   1    0      1   0    1               0  \n",
      "3    6700.0  3.900000    1   0    0      1   1    1               0  \n",
      "4    7300.0  4.600000    0   0    0      0   0    0               0  \n",
      "..      ...       ...  ...  ..  ...    ...  ..  ...             ...  \n",
      "395  6700.0  4.900000    0   0    0      0   0    0               1  \n",
      "396  7800.0  6.200000    0   0    0      0   0    0               1  \n",
      "397  6600.0  5.400000    0   0    0      0   0    0               1  \n",
      "398  7200.0  5.900000    0   0    0      0   0    0               1  \n",
      "399  6800.0  6.100000    0   0    0      0   0    0               1  \n",
      "\n",
      "[400 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "object_columns_list = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for object_column in object_columns_list:\n",
    "    df[object_column] = label_encoder.fit_transform(df[object_column].apply(lambda s: s.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4cb",
   "metadata": {},
   "source": [
    "Prepare the data by spliting into x and y, then into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b167c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.75\n",
    "val_split = 0.15\n",
    "test_split = 0.10\n",
    "\n",
    "x = df.drop('classification', axis=1)\n",
    "y = df['classification']\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=1 - train_split) # split into train and temp\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=test_split / (test_split + val_split)) # split temp into val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf841b6",
   "metadata": {},
   "source": [
    "Baseline model that predicts based on the most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de718ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        26\n",
      "           1       1.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.82      0.50      0.39        40\n",
      "weighted avg       0.77      0.65      0.51        40\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26  0]\n",
      " [14  0]]\n"
     ]
    }
   ],
   "source": [
    "baseline_model = DummyClassifier(strategy='most_frequent')\n",
    "baseline_model.fit(x_train, y_train)\n",
    "\n",
    "y_baseline_pred = baseline_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_baseline_pred))\n",
    "print(classification_report(y_test, y_baseline_pred, zero_division=1))\n",
    "cm = confusion_matrix(y_test, y_baseline_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bccfce",
   "metadata": {},
   "source": [
    "Not a very good model, of course.\n",
    "\n",
    "Let's try using a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a28dcd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26  0]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=9999) # increase limit on the number of iterations\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef620c6",
   "metadata": {},
   "source": [
    "Using a logistic regression model ended up achieving perfect accuracy for our test set (sometimes 0.975). Definitely better than the baseline model.\n",
    "\n",
    "We do care about recall, because FN is costly (incorrectly predicting that the patient does not have CKD), but that is high as well because the accuracy is 1 (or sometimes 0.975)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38148318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Coefficient  Absolute Coefficient\n",
      "14    hemo     1.238881              1.238881\n",
      "3       al    -1.176276              1.176276\n",
      "19      dm    -1.039291              1.039291\n",
      "18     htn    -1.005726              1.005726\n",
      "11      sc    -0.923304              0.923304\n",
      "22      pe    -0.857655              0.857655\n",
      "21   appet    -0.812574              0.812574\n",
      "17      rc     0.784960              0.784960\n",
      "5      rbc     0.630143              0.630143\n",
      "6       pc     0.623922              0.623922\n",
      "4       su    -0.469025              0.469025\n",
      "23     ane    -0.228043              0.228043\n",
      "15     pcv     0.176473              0.176473\n",
      "13     pot     0.142994              0.142994\n",
      "7      pcc    -0.121348              0.121348\n",
      "8       ba    -0.084545              0.084545\n",
      "12     sod     0.068796              0.068796\n",
      "1       bp    -0.054672              0.054672\n",
      "20     cad    -0.038520              0.038520\n",
      "2       sg     0.038275              0.038275\n",
      "9      bgr    -0.018043              0.018043\n",
      "10      bu     0.006989              0.006989\n",
      "0      age    -0.001839              0.001839\n",
      "16      wc     0.000123              0.000123\n"
     ]
    }
   ],
   "source": [
    "coefficients = model.coef_[0]\n",
    "feature_importance = pd.DataFrame({'Feature': x.columns, 'Coefficient': coefficients})\n",
    "\n",
    "feature_importance['Absolute Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297840d",
   "metadata": {},
   "source": [
    "As predicted from performing EDA, serum creatinine (sc), albumin (al), hemoglobin (hemo), and red blood cell counts (rc) are strong indicators in predicting whether a patient has CKD.\n",
    "\n",
    "However, packed cell volume (pcv) and specific gravity (sg), also from EDA, were not strong indicators in doing so.\n",
    "\n",
    "Obviously, over different trainings, the model has different coefficients for each feature, but the ones mentioned above are true across several different trainings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
